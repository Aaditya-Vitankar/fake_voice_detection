{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 11:47:20.351955: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-28 11:47:24.505603: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-28 11:47:24.505956: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-28 11:47:24.819461: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-28 11:47:26.256013: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-28 11:47:34.397613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "###-----------------\n",
    "### Import Libraries\n",
    "###-----------------\n",
    "\n",
    "import os\n",
    "import logging\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections.abc import Callable\n",
    "from typing import Literal\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch.autograd import Variable\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# for Frature Extraction\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "# =============================================================================================\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "''' to Extract feature from audio params:\n",
    "        file_path : <abs. path of the file(.wav format recoomended)>\n",
    "        segment_length : inverl for taking samples\n",
    "'''\n",
    "def extract_features(file_path, segment_length):   # Function to extract features from an audio file\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        y, sr = librosa.load(file_path) \n",
    "        #  Loading audio files returns \n",
    "        # y[audio time series. Multi-channel is supported]\n",
    "        # sr[sampling rate of y] Note: Taking default 22050\n",
    "        # [For more details : https://librosa.org/doc/0.10.1/generated/librosa.load.html]\n",
    "\n",
    "        \n",
    "        num_segments = int(np.ceil(len(y) / float(segment_length * sr))) \n",
    "        # Calculate the number of segments based on the segment length and audio length\n",
    "        \n",
    "        \n",
    "        features = [] \n",
    "        # Initialize a list to store the features for this file\n",
    "\n",
    "        \n",
    "        for i in range(num_segments): # Extracting features for each segment\n",
    "            \n",
    "            start_frame = i * segment_length * sr   # Calculate start for the current segment\n",
    "            end_frame = min(len(y), (i + 1) * segment_length * sr)    # Calculate  end frame for the current segment\n",
    "            # making sure the last frame does not excede the lenght of audio time series\n",
    "\n",
    "            \n",
    "            y_segment = y[start_frame:end_frame]# Extract audio for current segment of audio file\n",
    "\n",
    "\n",
    "            # Extract different features\n",
    "            chroma_stft = np.mean(librosa.feature.chroma_stft(y=y_segment, sr=sr))\n",
    "            # For more details : https://conference.scipy.org/proceedings/scipy2015/pdfs/brian_mcfee.pdf\n",
    "            rms = np.mean(librosa.feature.rms(y=y_segment))\n",
    "            spec_cent = np.mean(librosa.feature.spectral_centroid(y=y_segment, sr=sr))\n",
    "            spec_bw = np.mean(librosa.feature.spectral_bandwidth(y=y_segment, sr=sr))\n",
    "            rolloff = np.mean(librosa.feature.spectral_rolloff(y=y_segment, sr=sr))\n",
    "            zcr = np.mean(librosa.feature.zero_crossing_rate(y_segment))\n",
    "            mfccs = librosa.feature.mfcc(y=y_segment, sr=sr) # n_mfcc=20 by default\n",
    "            mfccs_mean = np.mean(mfccs, axis=1)\n",
    "            \n",
    "            # Append the extracted features to the list\n",
    "            features.append([chroma_stft, rms, spec_cent, spec_bw, rolloff, zcr, *mfccs_mean])\n",
    "\n",
    "        return features\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Function to create the dataset\n",
    "\n",
    "'''Creates the one sngle dataset for all audio file\n",
    "   with the dir name as a suffix as label\n",
    "   audio_dir = str : directory in with the file in\n",
    "   segment_length : inervel for taking samples\n",
    "'''\n",
    "\n",
    "def create_dataset(audio_dir, segment_length):\n",
    "    \n",
    "    labels = os.listdir(audio_dir) # Label for y\n",
    "    feature_list = []\n",
    "\n",
    "    # Iterate over all files in the audio_dir\n",
    "    for label in labels:\n",
    "        print(f'Processing {label} files...')\n",
    "        files = os.listdir(os.path.join(audio_dir, label))\n",
    "        # Wrap the files iterable with tqdm to show the progress bar\n",
    "        for file in files:\n",
    "            file_path = os.path.join(audio_dir, label, file)\n",
    "            # Extract features for the current file\n",
    "            file_features = extract_features(file_path, segment_length)\n",
    "            if file_features:\n",
    "                # Append features of all segments along with the label to the dataset\n",
    "                for segment_features in file_features:\n",
    "                    feature_list.append(segment_features + [label])\n",
    "                    \n",
    "    # Create a DataFrame with the dataset\n",
    "    df = pd.DataFrame(feature_list, columns=['chroma_stft', 'rms', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20','LABEL'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "# =============================================================================================\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "\n",
    "# Check GPU\n",
    "def check_GPU():\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "    try:\n",
    "        for g in gpus:\n",
    "            tf.config.experimental.set_memory_growth(g, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print (len(gpus), 'Phusical GPUs', len(logical_gpus), 'Logical GPUs')\n",
    "    except:\n",
    "        print ('invalid device')\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "# =============================================================================================\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Function to create the DataFrame\n",
    "\n",
    "'''Extracts Fetures from Audio and  returns DataFrame (Features Only)\n",
    "        File_path : Audio File Path\n",
    "        Segment_length : Length of Segment you want to extract fetures'''\n",
    "\n",
    "def create_DataFrame(File_path, segment_length):\n",
    "    feature_list =[]\n",
    "    file_features = extract_features(File_path, segment_length)\n",
    "    if file_features:\n",
    "        # Append features of all segments along with the label to the dataset\n",
    "        for segment_features in file_features:\n",
    "            feature_list.append(segment_features)\n",
    "                    \n",
    "    # Create a DataFrame with the dataset\n",
    "    df = pd.DataFrame(feature_list, columns=['chroma_stft', 'rms', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20'])\n",
    "    return df\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "# =============================================================================================\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Function to create the dataset\n",
    "\n",
    "'''Creates the seprate dataset for each of the audio file\n",
    "   with the dir name as a suffix as label\n",
    "   audio_dir = str : directory in with the file in\n",
    "   segment_length : inervel for taking samples\n",
    "   csv_output_path : path in whic you want ot store the csvs\n",
    "'''\n",
    "\n",
    "def create_dataset_sep(audio_dir, segment_length , csv_output_path):\n",
    "    \n",
    "    labels = os.listdir(audio_dir) # Label for y\n",
    "    \n",
    "\n",
    "    # Iterate over all files in the audio_dir\n",
    "    for label in labels:\n",
    "        print(f'Processing {label} files...')\n",
    "        files = os.listdir(os.path.join(audio_dir, label))\n",
    "        # Wrap the files iterable with tqdm to show the progress bar\n",
    "        for file in files:\n",
    "            file_path = os.path.join(audio_dir, label, file)\n",
    "\n",
    "            df = create_DataFrame(file_path, segment_length)\n",
    "\n",
    "            df['LABEL'] = [label for _ in range(len(df))]\n",
    "            fn_name = file.rstrip('.wav')\n",
    "            \n",
    "            df.to_csv(file_path+fn_name+\".csv\", index=False)\n",
    "\n",
    "            print(f'Dataset created and saved to {file_path}')\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "# =============================================================================================\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Logger\n",
    "\n",
    "'''Use to Keep Logs'''\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s %(name)s %(levelname)s %(message)s')\n",
    "def setup_logger(name, log_file, level=logging.INFO):\n",
    "    \"\"\"To set up as many loggers as you want\"\"\"\n",
    "    handler = logging.FileHandler(log_file)\n",
    "    handler.setFormatter(formatter)\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "    if logger.handlers:\n",
    "        logger.handlers = []\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "# =============================================================================================\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "\n",
    "'''use to Simulate AI Model when AI model is not Avilable (ONLY FOR DEVLOPMENT PERPOSE)'''\n",
    "\n",
    "def Dummy_predict(data = np.array):\n",
    "    if data.shape[2] == 26:\n",
    "        return np.random.choice(['REAL','FAKE'])\n",
    "    else:\n",
    "        return 'FAKE'\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "# =============================================================================================\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "    \n",
    "def reshape_data(data = pd.DataFrame ,label = 'NONE', time_step = 30 , time_interval = 10):\n",
    "\n",
    "    rem = len(data)% time_step\n",
    "    if rem!=0:\n",
    "        data = data.iloc[:-rem]\n",
    "    x_dim = data.shape[1]\n",
    "    y_dim = 1\n",
    "    z_dim = time_step\n",
    "    new_data = data.iloc[:time_step].to_numpy().reshape(y_dim,z_dim,x_dim)\n",
    "\n",
    "    for i in range(time_step,len(data)-time_step , time_interval):\n",
    "        part = data.iloc[i:i+time_step]\n",
    "        part = part.to_numpy().reshape(y_dim,z_dim,x_dim)\n",
    "        new_data = np.concatenate((new_data, part),axis=0)\n",
    "    \n",
    "    if label != 'NONE':\n",
    "        y_re = [label for _ in range(len(new_data))]\n",
    "        len(y_re)\n",
    "\n",
    "        return new_data , y_re\n",
    "    else:\n",
    "        return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###----------------\n",
    "### Some parameters\n",
    "###----------------\n",
    "\n",
    "inpDir = '../DATA/KAGGLE'\n",
    "outDir = '../DATA'\n",
    "subDir = 'csvs'\n",
    "audDir = \"AUDIO\"\n",
    "\n",
    "RANDOM_STATE = 24               # REMEMBER: to remove at the time of promotion to production\n",
    "np.random.seed(RANDOM_STATE)    # Set Random Seed for reproducible  results\n",
    "\n",
    "EPOCHS = 11                     # number of epochs\n",
    "ALPHA = 0.001                   # learning rate\n",
    "NUM_SAMPLES = 1280              # How many samples we want to generate \n",
    "NOISE = 0.2                     # Noise to be introduced in the data\n",
    "TEST_SIZE = 0.2\n",
    "BATCH_SIZE = 26\n",
    "PATIENCE = 20\n",
    "\n",
    "# parameters for Matplotlib\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 8),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'\n",
    "         }\n",
    "\n",
    "CMAP = 'coolwarm' # plt.cm.Spectral\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rms</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [chroma_stft, rms, spectral_centroid, spectral_bandwidth, rolloff, zero_crossing_rate, mfcc1, mfcc2, mfcc3, mfcc4, mfcc5, mfcc6, mfcc7, mfcc8, mfcc9, mfcc10, mfcc11, mfcc12, mfcc13, mfcc14, mfcc15, mfcc16, mfcc17, mfcc18, mfcc19, mfcc20, LABEL]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../DATA/csvs/biden-original_REAL.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
