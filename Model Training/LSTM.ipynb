{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets import some libraries\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic parameters\n",
    "\n",
    "inpDir = '../../input' # location where input data is stored\n",
    "outDir = '../output' # location to store outputs\n",
    "\n",
    "RANDOM_STATE = 24 # for initialization ----- REMEMBER: to remove at the time of promotion to production\n",
    "np.random.seed(RANDOM_STATE) # Set Random Seed for reproducible results\n",
    "\n",
    "EPOCHS = 500  # number of cycles to run\n",
    "\n",
    "ALPHA = 0.1  # learning rate\n",
    "\n",
    "TEST_SIZE = 0.2 # What fraction we want to keep for testing\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Set parameters for decoration of plots\n",
    "params = {'legend.fontsize' : 'large',\n",
    "          'figure.figsize'  : (12,9),\n",
    "          'axes.labelsize'  : 'x-large',\n",
    "          'axes.titlesize'  :'x-large',\n",
    "          'xtick.labelsize' :'large',\n",
    "          'ytick.labelsize' :'large',\n",
    "         }\n",
    "CMAP = plt.cm.brg\n",
    "\n",
    "plt.rcParams.update(params) # update rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-----------------------------------\n",
    "### Function to plot Loss Curve\n",
    "###-----------------------------------\n",
    "\n",
    "def plot_tf_hist(hist_df):\n",
    "    '''\n",
    "    Args:\n",
    "      hist_df : pandas Dataframe with four columns\n",
    "                For 'x' values, we will use index\n",
    "    '''\n",
    "    fig, axes = plt.subplots(1,2 , figsize = (15,6))\n",
    "\n",
    "    # properties  matplotlib.patch.Patch \n",
    "    props = dict(boxstyle='round', facecolor='aqua', alpha=0.4)\n",
    "    facecolor = 'cyan'\n",
    "    fontsize=12\n",
    "    \n",
    "    # Get columns by index to eliminate any column naming error\n",
    "    y1 = hist_df.columns[0]\n",
    "    y2 = hist_df.columns[1]\n",
    "    y3 = hist_df.columns[2]\n",
    "    y4 = hist_df.columns[3]\n",
    "\n",
    "    # Where was min loss\n",
    "    best = hist_df[hist_df[y3] == hist_df[y3].min()]\n",
    "    \n",
    "    ax = axes[0]\n",
    "\n",
    "    hist_df.plot(y = [y1,y3], ax = ax, colormap=CMAP)\n",
    "\n",
    "\n",
    "    # little beautification\n",
    "    txtFmt = \"Loss: \\n  train: {:6.4f}\\n   test: {:6.4f}\"\n",
    "    txtstr = txtFmt.format(hist_df.iloc[-1][y1],\n",
    "                           hist_df.iloc[-1][y3]) #text to plot\n",
    "    \n",
    "    # place a text box in upper middle in axes coords\n",
    "    ax.text(0.3, 0.95, txtstr, transform=ax.transAxes, fontsize=fontsize,\n",
    "            verticalalignment='top', bbox=props)\n",
    "\n",
    "    # Mark arrow at lowest\n",
    "    ax.annotate(f'Min: {best[y3].to_numpy()[0]:6.4f}', # text to print\n",
    "                xy=(best.index.to_numpy(), best[y3].to_numpy()[0]), # Arrow start\n",
    "                xytext=(best.index.to_numpy()-1, best[y3].to_numpy()[0]), # location of text \n",
    "                fontsize=fontsize, va='bottom', ha='right',bbox=props, # beautification of text\n",
    "                arrowprops=dict(facecolor=facecolor, shrink=0.05)) # arrow\n",
    "\n",
    "    # Draw vertical line at best value\n",
    "    ax.axvline(x = best.index.to_numpy(), color = 'green', linestyle='-.', lw = 3);\n",
    "\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(y1.capitalize())\n",
    "    ax.set_title('Errors')\n",
    "    ax.grid();\n",
    "    ax.legend(loc = 'upper left') # model legend to upper left\n",
    "\n",
    "    ax = axes[1]\n",
    "\n",
    "    hist_df.plot( y = [y2, y4], ax = ax, colormap=CMAP)\n",
    "    \n",
    "    # little beautification\n",
    "    txtFmt = \"Accuracy: \\n  train: {:6.4f}\\n  test:  {:6.4f}\"\n",
    "    txtstr = txtFmt.format(hist_df.iloc[-1][y2],\n",
    "                           hist_df.iloc[-1][y4]) #text to plot\n",
    "\n",
    "    # place a text box in upper middle in axes coords\n",
    "    ax.text(0.3, 0.2, txtstr, transform=ax.transAxes, fontsize=fontsize,\n",
    "            verticalalignment='top', bbox=props)\n",
    "\n",
    "    # Mark arrow at lowest\n",
    "    ax.annotate(f'Best: {best[y4].to_numpy()[0]:6.4f}', # text to print\n",
    "                xy=(best.index.to_numpy(), best[y4].to_numpy()[0]), # Arrow start\n",
    "                xytext=(best.index.to_numpy()-1, best[y4].to_numpy()[0]), # location of text \n",
    "                fontsize=fontsize, va='bottom', ha='right',bbox=props, # beautification of text\n",
    "                arrowprops=dict(facecolor=facecolor, shrink=0.05)) # arrow\n",
    "    \n",
    "    \n",
    "    # Draw vertical line at best value\n",
    "    ax.axvline(x = best.index.to_numpy(), color = 'green', linestyle='-.', lw = 3);\n",
    "\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(y2.capitalize())\n",
    "    ax.grid()\n",
    "    ax.legend(loc = 'lower left')\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 13:45:39.451127: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-28 13:45:39.501718: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-28 13:45:39.501756: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-28 13:45:39.503012: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-28 13:45:39.510895: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-28 13:45:40.570488: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, '../Resources')\n",
    "\n",
    "import lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing REAL files...\n",
      "Error processing ../DATA/LSTM Train Test Split/Audio/train/REAL/biden-original.wav: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/Desktop/Puneet_project/Project/Model Training/../Resources/lib.py:54: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(file_path)\n",
      "/home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created and saved to ../DATA/LSTM Train Test Split/train_csv/biden-original.csv\n",
      "Dataset created and saved to ../DATA/LSTM Train Test Split/train_csv/obama-original.csv\n",
      "Dataset created and saved to ../DATA/LSTM Train Test Split/train_csv/margot-original.csv\n",
      "Dataset created and saved to ../DATA/LSTM Train Test Split/train_csv/ryan-original.csv\n",
      "Dataset created and saved to ../DATA/LSTM Train Test Split/train_csv/linus-original.csv\n",
      "Dataset created and saved to ../DATA/LSTM Train Test Split/train_csv/musk-original.csv\n",
      "Dataset created and saved to ../DATA/LSTM Train Test Split/train_csv/taylor-original.csv\n",
      "Processing FAKE files...\n",
      "Dataset created and saved to ../DATA/LSTM Train Test Split/train_csv/ryan-to-taylor.csv\n",
      "Dataset created and saved to ../DATA/LSTM Train Test Split/train_csv/biden-to-taylor.csv\n",
      "Dataset created and saved to ../DATA/LSTM Train Test Split/train_csv/musk-to-margot.csv\n",
      "Dataset created and saved to ../DATA/LSTM Train Test Split/train_csv/linus-to-trump.csv\n",
      "Dataset created and saved to ../DATA/LSTM Train Test Split/train_csv/taylor-to-trump.csv\n",
      "Dataset created and saved to ../DATA/LSTM Train Test Split/train_csv/biden-to-Obam.csv\n",
      "Dataset created and saved to ../DATA/LSTM Train Test Split/train_csv/taylor-to-linus.csv\n",
      "Dataset created and saved to ../DATA/LSTM Train Test Split/train_csv/margot-to-musk.csv\n"
     ]
    }
   ],
   "source": [
    "lib.create_dataset_sep(audio_dir=\"../DATA/LSTM Train Test Split/Audio/train\",segment_length=1 , csv_output_path='../DATA/LSTM Train Test Split/train_csv/')\n",
    "lib.create_dataset_sep(audio_dir=\"../DATA/LSTM Train Test Split/Audio/test\",segment_length=1 , csv_output_path='../DATA/LSTM Train Test Split/test_csv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa==0.8.1\n",
      "  Downloading librosa-0.8.1-py3-none-any.whl (203 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.8/203.8 kB\u001b[0m \u001b[31m343.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from librosa==0.8.1) (3.0.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from librosa==0.8.1) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from librosa==0.8.1) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from librosa==0.8.1) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from librosa==0.8.1) (1.3.2)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from librosa==0.8.1) (5.1.1)\n",
      "Collecting resampy>=0.2.2 (from librosa==0.8.1)\n",
      "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numba>=0.43.0 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from librosa==0.8.1) (0.58.1)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from librosa==0.8.1) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from librosa==0.8.1) (1.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from librosa==0.8.1) (23.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from numba>=0.43.0->librosa==0.8.1) (0.41.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from pooch>=1.0->librosa==0.8.1) (4.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from pooch>=1.0->librosa==0.8.1) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.1) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from soundfile>=0.10.2->librosa==0.8.1) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.8.1) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dai/anaconda3/envs/DNN/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (2023.11.17)\n",
      "Installing collected packages: resampy, librosa\n",
      "  Attempting uninstall: librosa\n",
      "    Found existing installation: librosa 0.10.1\n",
      "    Uninstalling librosa-0.10.1:\n",
      "      Successfully uninstalled librosa-0.10.1\n",
      "Successfully installed librosa-0.8.1 resampy-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install librosa==0.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.reshape_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
